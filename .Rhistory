library(pacman)
p_load(tidyverse,ggplot2)
dta<-read.csv("data/cleaned/the_data.csv")
View(dta)
dta$state
dta0<-dta
dta<-dta%>%
filter(!is.na(median_age))
View(dta)
library(pacman)
p_load(tidyverse,ggplot2)
dta<-read.csv("data/cleaned/the_data.csv")
library(pacman)
p_load(tidyverse,ggplot2)
dta<-read.csv("data/cleaned/the_data.csv")
dta0<-dta
dta<-dta%>%
filter(!is.na(median_age))
View(dta)
colnames(dta)
View(dta)
test<-dta%>%
filter(year=2018)
test<-dta%>%
filter(year==2018)
View(test)
ggplot(data = dta, aes(x = city, y = year, fill = negative_rate)) +
geom_tile(color = "white") +
scale_fill_gradient2(
low = "blue",
high = "red",
mid = "white",
midpoint = 0,
limit = c(-1,1),
name = "Correlation"
) +
theme_minimal() +
coord_fixed() +
theme(
axis.text.x = element_text(angle = 45, vjust = 1, size = 10, hjust = 1),
axis.title.x = element_blank(),
axis.title.y = element_blank()
)
ggplot(data = dta, aes(x = city, y = year, fill = negative_rate)) +
geom_tile(color = "white") +
scale_fill_gradient2(
low = "blue",
high = "red",
mid = "white",
midpoint = 0,
limit = c(-1,1),
name = "Correlation"
) +
theme_minimal() +
coord_fixed() +
)
ggplot(data = dta, aes(x = city, y = year, fill = negative_rate)) +
geom_tile(color = "white") +
scale_fill_gradient2(
low = "blue",
high = "red",
mid = "white",
midpoint = 0,
limit = c(-1,1),
name = "Correlation"
) +
theme_minimal() +
coord_fixed()
)
ggplot(data = dta, aes(x = city, y = year, fill = negative_rate)) +
geom_tile(color = "white") +
theme_minimal() +
coord_fixed()
)
dta_heat<-dta%>%
sort(total_observations,decreasing = TRUE)
dta_heat<-dta%>%
arrange(total_observations,desc = TRUE)
ggplot(data = dta_heat, aes(x = city, y = year, fill = negative_rate)) +
geom_tile(color = "white") +
theme_minimal() +
coord_fixed()
)
dta_heat<-dta%>%
arrange(total_observations,desc = TRUE)
ggplot(data = dta_heat, aes(x = city, y = year, fill = negative_rate)) +
geom_tile(color = "white") +
theme_minimal() +
coord_fixed()
)
dta_heat<-dta%>%
arrange(total_observations,desc = TRUE)
ggplot(data = dta_heat, aes(x = city, y = year, fill = negative_rate)) +
geom_tile(color = "white") +
theme_minimal() +
coord_fixed()
View(dta_heat)
dta_heat <- dta %>%
mutate(city = fct_reorder(city, total_observations, .desc = TRUE))
ggplot(data = dta_heat, aes(x = city, y = year, fill = negative_rate)) +
geom_tile(color = "white") +
theme_minimal() +
coord_fixed()
library(pacman)
library(readxl)
p_load(tidyverse,ggplot2)
dta <- read_excel("final_data.xlsx")
library(pacman)
library(readxl)
p_load(tidyverse,ggplot2)
dta <- read_excel("data/cleaned/final_data.xlsx")
View(dta)
model_a<-lm(negative_rate~density+income+average_years_schooling + mean_work_hours + mental_health_provider_rate, data= dta)
summary(model_a)
model_b<-lm(negative_submission_rate~density+average_years_schooling+income+ mean_work_hours + mental_health_provider_rate, data= dta)
summary(model_b)
model_c<-lm(negative_comment_rate~density+average_years_schooling+income+ mean_work_hours + mental_health_provider_rate, data= dta)
summary(model_c)
model_test<-lm(negative_rate~density+average_years_schooling+income+ mean_work_hours + mental_health_provider_rate, data= dta)
summary(model_test)
dta_heat <- dta %>%
mutate(city = fct_reorder(city, total_observations, .desc = TRUE))
ggplot(data = dta_heat, aes(x = city, y = year, fill = negative_rate)) +
geom_tile(color = "white") +
theme_minimal() +
coord_fixed()
library(ggplot2)
library(dplyr)
library(forcats)
dta_heat <- dta %>%
mutate(city = fct_reorder(city, total_observations, .desc = TRUE))
ggplot(data = dta_heat, aes(x = city, y = factor(year), fill = negative_rate)) +
geom_tile(color = "white", linewidth = 0.5) +
scale_fill_gradient(low = "#fff200", high = "#8b00ff") +
theme_minimal(base_size = 14) +
theme(
axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
axis.text.y = element_text(size = 12),
legend.title = element_text(size = 12),
legend.text = element_text(size = 10),
plot.title = element_text(size = 18, face = "bold")
) +
labs(
title = "Negative Rate by City and Year",
x = "City",
y = "Year",
fill = "Negative Rate"
) +
coord_fixed()
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
tidyverse,
stm,
lubridate,
quanteda,
reshape2,  # For melt()
tidytext,  # For tidy()
ggpubr,    # For theme_pubr()
knitr,     # For kable()
igraph
)
# ==============================================================================
# 1. LOAD DATA & FUNCTIONS
# ==============================================================================
# Load the data
out <- readRDS("models/inputs/depression/out.rds")
dta <- readRDS("models/inputs/depression/dta.rds")
# Extract components
docs <- out$documents
vocab <- out$vocab
meta <- out$meta
# --- Define Helper Function: Comprehensive Analysis ---
analyze_topic_model <- function(topic_models_list, estimates_list, custom_labels = NULL) {
for (i in seq_along(topic_models_list)) {
topic_model <- topic_models_list[[i]]
# Check if estimate exists for this model
topic_key <- names(topic_models_list)[i]
if (!topic_key %in% names(estimates_list)) {
warning(paste("No estimate found for", topic_key, "- skipping."))
next
}
estimate_model <- estimates_list[[topic_key]]
topic_number <- topic_model$settings$dim$K
print(paste("Analyzing Model with K =", topic_number))
# --- Handle Labels ---
# If no labels provided (or length mismatch), default to "Topic X"
if (is.null(custom_labels) || length(custom_labels) != topic_number) {
if(!is.null(custom_labels)) warning("Label count does not match K. Using defaults.")
model_labels <- paste("Topic", 1:topic_number)
} else {
model_labels <- custom_labels
}
# Create a lookup dataframe for easy merging
label_df <- data.frame(topic = 1:topic_number, label_text = model_labels)
# --- Create Directory ---
output_dir <- paste0("plots/stm/model_K", topic_number, "/")
dir.create(output_dir, recursive = TRUE, showWarnings = FALSE)
# 1. Label Topics (Algo based)
top_words <- labelTopics(topic_model, topics = c(1:topic_number), n = 10, frexweight = 0.5)
# 2. Topic Proportions (Gamma)
gamma <- tidy(topic_model, matrix = "gamma", document_names = rownames(meta)) %>%
group_by(topic) %>%
summarise(gamma = mean(gamma)) %>%
left_join(label_df, by = "topic") %>%  # Join custom labels
arrange(desc(gamma)) %>%
mutate(topic_label = paste0(topic, ": ", label_text),
topic_label = reorder(topic_label, gamma))
# 3. Find Thoughts
thought <- findThoughts(topic_model, texts = out$meta$text, n = 15)
# 4. Dominant Topic
dominant_topic <- data.frame(dominant_topic = apply(topic_model$theta, 1, which.max))
# 5. Output Text Report
sink(paste0(output_dir, "analysis.txt"), split = TRUE)
print("--- Summary ---")
summary(topic_model, frexweight = 0.5)
print("--- Gamma (Expected Proportions) ---")
print(kable(gamma, digits = 3, col.names = c("Topic", "Mean Gamma", "Label", "Combined")))
print("--- Top Thoughts ---")
print(thought)
sink()
# 6. Plot: Top Word Proportions (Single Plot)
top_words_1 <- tidy(topic_model, matrix = "beta") %>%
group_by(topic) %>%
slice_max(beta, n = 1) %>%
left_join(label_df, by="topic") %>% # Join labels
arrange(topic, -beta)
p1 <- ggplot(top_words_1, aes(x = beta, y = factor(label_text, levels = model_labels))) +
geom_col(fill = "gray70") +
geom_text(aes(label = term), hjust = 0, size = 4) +
theme_minimal() +
xlim(0, max(top_words_1$beta) + 0.05) +
labs(title = paste0("Top Words (K=", topic_number, ")"), x = "Beta", y = "Topic")
ggsave(paste0(output_dir, "top_word_single.png"), plot = p1, bg="white")
# 7. Plot: Top Words Bar Charts (Facet)
max_beta <- tidy(topic_model, matrix = "beta") %>%
filter(beta > .001) %>%
summarise(max = max(beta)) %>% pull(max)
p2 <- tidy(topic_model, matrix = "beta") %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
left_join(label_df, by="topic") %>% # Join labels
mutate(topic_name = factor(label_text, levels = model_labels),
term = reorder_within(term, beta, topic_name)) %>%
ggplot(aes(x = term, y = beta, fill = topic_name)) +
geom_col(show.legend = FALSE) +
scale_y_continuous(limits = c(0, max_beta)) +
facet_wrap(~ topic_name, scales = "free_y") + # Facet by Name
coord_flip() +
scale_x_reordered() +
labs(x = NULL, y = "Beta") +
theme_pubr() +
theme(axis.text.y = element_text(size = 7))
ggsave(paste0(output_dir, "topwords_facet.png"),
plot = p2, width = 14, height = 12, bg="white")
# 8. Plot: Topic Correlations (Network)
png(paste0(output_dir, "corr_network.png"), width = 1000, height = 800)
topic_corr <- topicCorr(topic_model, cutoff = 0.03)
# Use custom labels for vertices
plot(topic_corr, vertex.label = model_labels, vertex.label.cex = 0.8)
dev.off()
# 9. Plot: Prevalence (Date)
png(paste0(output_dir, "prevalence.png"), width = 3000, height = 3000, res = 300)
par(mfrow = c(ceiling(topic_number / 4), 4), mar = c(4, 4, 2, 1))
for (k in 1:topic_number) {
plot.estimateEffect(
estimate_model,
covariate = "date_numeric",
method = "continuous",
topics = c(k),
main = model_labels[k], # Use Custom Label as Title
xlab = "Time",
linecol = "blue"
)
}
dev.off()
}
}
# ==============================================================================
# 2. RUN ANALYSIS
# ==============================================================================
# Load your specific model
topic_model <- readRDS("models/R_topic_model/stm_topic_model_15.rds")
estimated_model <- readRDS("models/R_topic_model/stm_topic_model_estimated_15.rds")
# Prepare lists
my_models <- list(topic_model = topic_model)
my_estimates <- list(topic_model = estimated_model)
# ------------------------------------------------------------------------------
# INPUT REQUIRED: DEFINE YOUR LABELS HERE
# ------------------------------------------------------------------------------
# Since you have K=15, you must provide exactly 15 labels in order (1 to 15).
# Replace these strings with your actual topic names based on your previous analysis.
my_topic_labels <- c(
"1. Sports Venting",             # Aggressive sports ranting (Bruins/Columbus)
"2. Chicago 'Depression' Dogs",  # Specific hot dog style & pets
"3. NBA/Celtics Fandom",         # Basketball performance discussions
"4. Clinical Treatment/Meds",    # Therapy, psychiatrists, prescriptions
"5. Politics & Economy",         # Elections, government, tariffs
"6. Suicide Resources",          # Hotlines and help bots
"7. Transgender Mental Health",  # Gender-affirming care studies
"8. Casual Reactions",           # Calling things "depressing"
"9. Suicide Philosophy (DFW)",   # David Foster Wallace quotes
"10. Urban Planning & Transit",  # Public transport and city infrastructure
"11. Loneliness & Socializing",  # Making friends and advice
"12. Seasonal Affective Disorder", # Weather, winter, Seattle/Chicago
"13. Anecdotes & Lyrics",        # Personal stories and song lyrics
"14. Cost of Living/Housing",    # Rent, budgets, real estate
"15. Academic Struggles"         # GPA, failing classes, university stress
)
# ------------------------------------------------------------------------------
# Run the Function with Labels
# ------------------------------------------------------------------------------
analyze_topic_model(my_models, my_estimates, custom_labels = my_topic_labels)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
tidyverse,
stm,
lubridate,
quanteda,
reshape2,  # For melt()
tidytext,  # For tidy()
ggpubr,    # For theme_pubr()
knitr,     # For kable()
igraph
)
# ==============================================================================
# 1. LOAD DATA & FUNCTIONS
# ==============================================================================
# Load the data
out <- readRDS("models/inputs/depression/out.rds")
dta <- readRDS("models/inputs/depression/dta.rds")
# Extract components
docs <- out$documents
vocab <- out$vocab
meta <- out$meta
# --- Define Helper Function: Comprehensive Analysis ---
analyze_topic_model <- function(topic_models_list, estimates_list, custom_labels = NULL) {
for (i in seq_along(topic_models_list)) {
topic_model <- topic_models_list[[i]]
# Check if estimate exists for this model
topic_key <- names(topic_models_list)[i]
if (!topic_key %in% names(estimates_list)) {
warning(paste("No estimate found for", topic_key, "- skipping."))
next
}
estimate_model <- estimates_list[[topic_key]]
topic_number <- topic_model$settings$dim$K
print(paste("Analyzing Model with K =", topic_number))
# --- Handle Labels ---
if (is.null(custom_labels) || length(custom_labels) != topic_number) {
if(!is.null(custom_labels)) warning("Label count does not match K. Using defaults.")
model_labels <- paste("Topic", 1:topic_number)
} else {
model_labels <- custom_labels
}
# Create a lookup dataframe for easy merging
label_df <- data.frame(topic = 1:topic_number, label_text = model_labels)
# --- Create Directory ---
output_dir <- paste0("plots/stm/model_K", topic_number, "/")
dir.create(output_dir, recursive = TRUE, showWarnings = FALSE)
# 1. Label Topics (Algo based)
top_words <- labelTopics(topic_model, topics = c(1:topic_number), n = 10, frexweight = 0.5)
# 2. Topic Proportions (Gamma)
gamma <- tidy(topic_model, matrix = "gamma", document_names = rownames(meta)) %>%
group_by(topic) %>%
summarise(gamma = mean(gamma)) %>%
left_join(label_df, by = "topic") %>%
arrange(desc(gamma)) %>%
mutate(topic_label = paste0(topic, ": ", label_text),
topic_label = reorder(topic_label, gamma))
# 3. Find Thoughts
thought <- findThoughts(topic_model, texts = out$meta$text, n = 15)
# 4. Dominant Topic
dominant_topic <- data.frame(dominant_topic = apply(topic_model$theta, 1, which.max))
# 5. Output Text Report
sink(paste0(output_dir, "analysis.txt"), split = TRUE)
print("--- Summary ---")
summary(topic_model, frexweight = 0.5)
print("--- Gamma (Expected Proportions) ---")
print(kable(gamma, digits = 3, col.names = c("Topic", "Mean Gamma", "Label", "Combined")))
print("--- Top Thoughts ---")
print(thought)
sink()
# 6. Plot: Top Word Proportions (Single Plot)
top_words_1 <- tidy(topic_model, matrix = "beta") %>%
group_by(topic) %>%
slice_max(beta, n = 1) %>%
left_join(label_df, by="topic") %>%
arrange(topic, -beta)
p1 <- ggplot(top_words_1, aes(x = beta, y = factor(label_text, levels = model_labels))) +
geom_col(fill = "gray70") +
geom_text(aes(label = term), hjust = 0, size = 4) +
theme_minimal() +
xlim(0, max(top_words_1$beta) + 0.05) +
labs(title = paste0("Top Words (K=", topic_number, ")"), x = "Beta", y = "Topic")
ggsave(paste0(output_dir, "top_word_single.png"), plot = p1, bg="white")
# 7. Plot: Top Words Bar Charts (Facet)
max_beta <- tidy(topic_model, matrix = "beta") %>%
filter(beta > .001) %>%
summarise(max = max(beta)) %>% pull(max)
p2 <- tidy(topic_model, matrix = "beta") %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
left_join(label_df, by="topic") %>%
mutate(topic_name = factor(label_text, levels = model_labels),
term = reorder_within(term, beta, topic_name)) %>%
ggplot(aes(x = term, y = beta, fill = topic_name)) +
geom_col(show.legend = FALSE) +
scale_y_continuous(limits = c(0, max_beta)) +
facet_wrap(~ topic_name, scales = "free_y") +
coord_flip() +
scale_x_reordered() +
labs(x = NULL, y = "Beta") +
theme_pubr() +
theme(axis.text.y = element_text(size = 7))
ggsave(paste0(output_dir, "topwords_facet.png"),
plot = p2, width = 14, height = 12, bg="white")
# 8. Plot: Topic Correlations (Network)
# FIX: Changed 'vertex.label' to 'vlabels'
png(paste0(output_dir, "corr_network.png"), width = 1000, height = 800)
topic_corr <- topicCorr(topic_model, cutoff = 0.03)
tryCatch({
plot(topic_corr, vlabels = model_labels, vertex.label.cex = 0.8)
}, error = function(e) {
message("Network plot failed (likely low correlation or cutoff issues): ", e$message)
})
dev.off()
# 9. Plot: Prevalence (Date)
png(paste0(output_dir, "prevalence.png"), width = 3000, height = 3000, res = 300)
par(mfrow = c(ceiling(topic_number / 4), 4), mar = c(4, 4, 2, 1))
for (k in 1:topic_number) {
plot.estimateEffect(
estimate_model,
covariate = "date_numeric",
method = "continuous",
topics = c(k),
main = model_labels[k],
xlab = "Time",
linecol = "blue"
)
}
dev.off()
}
}
# ==============================================================================
# 2. RUN ANALYSIS
# ==============================================================================
# Load your specific model
topic_model <- readRDS("models/R_topic_model/stm_topic_model_15.rds")
estimated_model <- readRDS("models/R_topic_model/stm_topic_model_estimated_15.rds")
# Prepare lists
my_models <- list(topic_model = topic_model)
my_estimates <- list(topic_model = estimated_model)
# ------------------------------------------------------------------------------
# INPUT REQUIRED: DEFINE YOUR LABELS HERE
# ------------------------------------------------------------------------------
# Since you have K=15, you must provide exactly 15 labels in order (1 to 15).
# Replace these strings with your actual topic names based on your previous analysis.
my_topic_labels <- c(
"1. Sports Venting",             # Aggressive sports ranting (Bruins/Columbus)
"2. Chicago 'Depression' Dogs",  # Specific hot dog style & pets
"3. NBA/Celtics Fandom",         # Basketball performance discussions
"4. Clinical Treatment/Meds",    # Therapy, psychiatrists, prescriptions
"5. Politics & Economy",         # Elections, government, tariffs
"6. Suicide Resources",          # Hotlines and help bots
"7. Transgender Mental Health",  # Gender-affirming care studies
"8. Casual Reactions",           # Calling things "depressing"
"9. Suicide Philosophy (DFW)",   # David Foster Wallace quotes
"10. Urban Planning & Transit",  # Public transport and city infrastructure
"11. Loneliness & Socializing",  # Making friends and advice
"12. Seasonal Affective Disorder", # Weather, winter, Seattle/Chicago
"13. Anecdotes & Lyrics",        # Personal stories and song lyrics
"14. Cost of Living/Housing",    # Rent, budgets, real estate
"15. Academic Struggles"         # GPA, failing classes, university stress
)
# ------------------------------------------------------------------------------
# Run the Function with Labels
# ------------------------------------------------------------------------------
analyze_topic_model(my_models, my_estimates, custom_labels = my_topic_labels)
library(readr)
depression_corpus_predicted <- read_csv("data/cleaned/depression_corpus_predicted.csv")
View(depression_corpus_predicted)
library(readr)
all_words_corpus_predicted <- read_csv("data/cleaned/all_words_corpus_predicted.csv")
View(all_words_corpus_predicted)
table(all_words_corpus_predicted$is_negative)
table(depression_corpus_predicted$is_negative)
df<-all_words_corpus_predicted%>%filter(is_negative==1)
library(tidyverse)
df<-all_words_corpus_predicted%>%filter(is_negative==1)
table(df$city)
